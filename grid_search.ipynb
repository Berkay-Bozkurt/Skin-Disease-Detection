{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis stack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data visualization stack\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# miscellaneous\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# deep learning stack\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import (\n",
    "    ResNet50,\n",
    "    preprocess_input,\n",
    "    decode_predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACK', 'BCC', 'MEL', 'NEV', 'SCC', 'SEK']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASSES = os.listdir('./cancer/Cancer/')\n",
    "CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 900 images belonging to 6 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((900, 224, 224, 3), (900, 6))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen = image.ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "train_data_gen = data_gen.flow_from_directory(\n",
    "        directory='./cancer/Cancer/',\n",
    "        class_mode=\"categorical\",\n",
    "        classes=CLASSES,\n",
    "        batch_size=900,\n",
    "        target_size=(224,224)\n",
    ")\n",
    "\n",
    "xtrain, ytrain = next(train_data_gen)\n",
    "xtrain.shape, ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "BASE_MODEL = ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "BASE_MODEL.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HyperModel(hyperparameters):\n",
    "    '''\n",
    "    creates a hypermodel by stacking dense layers on top of base model.\n",
    "    Three hyperparameters to be tuned:\n",
    "    1. number of neurons in the first dense layer,\n",
    "    2. number of neurons in the second dense layer,\n",
    "    3. number of neurons in the third dense layer,\n",
    "    4. initial learning rate of the optimizer\n",
    "    Args:\n",
    "    hyperparameters - Keras tuner object\n",
    "    '''\n",
    "    # initialize the Sequential API to stack the layers\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # convolutional base \n",
    "    model.add(BASE_MODEL)\n",
    "    \n",
    "    # number of neurons in the first dense layer\n",
    "    hp_units1 = hyperparameters.Choice('units1', values=[2048,512,256])\n",
    "    # first dense layer\n",
    "    model.add(keras.layers.Dense(units=hp_units1, activation='relu'))\n",
    "    \n",
    "    # number of neurons in the second dense layer\n",
    "    hp_units2 = hyperparameters.Choice('units2', values=[512,256,128])\n",
    "    # second dense layer\n",
    "    model.add(keras.layers.Dense(units=hp_units2, activation='relu'))\n",
    "    \n",
    "    # number of neurons in the third dense layer\n",
    "    hp_units3 = hyperparameters.Choice('units3', values=[[256,128,64,32,16]])\n",
    "    # third dense layer\n",
    "    model.add(keras.layers.Dense(units=hp_units3, activation='relu'))\n",
    "    \n",
    "    # dropout \n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    \n",
    "    # output layer with softmax activation function\n",
    "    model.add(keras.layers.Dense(len(CLASSES), activation='softmax'))\n",
    "    \n",
    "    # learning rate for the optimizer\n",
    "    hp_learning_rate = hyperparameters.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            learning_rate=hp_learning_rate\n",
    "        ),\n",
    "        loss=keras.losses.categorical_crossentropy,\n",
    "        metrics=[keras.metrics.categorical_accuracy]\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "# instantiate hyperband\n",
    "tuner = kt.GridSearch(\n",
    "    hypermodel=HyperModel,\n",
    "    objective='val_categorical_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "units1 (Choice)\n",
      "{'default': 2048, 'conditions': [], 'values': [2048, 512, 256], 'ordered': True}\n",
      "units2 (Choice)\n",
      "{'default': 512, 'conditions': [], 'values': [512, 256, 128], 'ordered': True}\n",
      "units3 (Choice)\n",
      "{'default': 256, 'conditions': [], 'values': [256, 128, 64, 32, 16], 'ordered': True}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "# hypertuning settings summary\n",
    "tuner.search_space_summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping\n",
    "stop_early = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #32\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "2048              |2048              |units1\n",
      "128               |512               |units2\n",
      "256               |128               |units3\n",
      "0.001             |0.001             |learning_rate\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 235, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 213, in _build_and_fit_model\n",
      "    model = self._try_build(hp)\n",
      "  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 155, in _try_build\n",
      "    model = self._build_hypermodel(hp)\n",
      "  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 146, in _build_hypermodel\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"C:\\Users\\berka\\AppData\\Local\\Temp\\ipykernel_4256\\1118035448.py\", line 29, in HyperModel\n",
      "    hp_units3 = hyperparameters.Choice('units3', values=[[256,128,64,32,16]])\n",
      "  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\hyperparameters\\hyperparameters.py\", line 288, in Choice\n",
      "    hp = hp_types.Choice(\n",
      "  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\hyperparameters\\hp_types\\choice_hp.py\", line 65, in __init__\n",
      "    raise TypeError(\n",
      "TypeError: A `Choice` can contain only `int`, `float`, `str`, or `bool`, found values: [[256, 128, 64, 32, 16]]with types: <class 'list'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures excceeded the limit of 3.\nTraceback (most recent call last):\n  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 235, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 213, in _build_and_fit_model\n    model = self._try_build(hp)\n  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 155, in _try_build\n    model = self._build_hypermodel(hp)\n  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 146, in _build_hypermodel\n    model = self.hypermodel.build(hp)\n  File \"C:\\Users\\berka\\AppData\\Local\\Temp\\ipykernel_4256\\1118035448.py\", line 29, in HyperModel\n    hp_units3 = hyperparameters.Choice('units3', values=[[256,128,64,32,16]])\n  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\hyperparameters\\hyperparameters.py\", line 288, in Choice\n    hp = hp_types.Choice(\n  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\hyperparameters\\hp_types\\choice_hp.py\", line 65, in __init__\n    raise TypeError(\nTypeError: A `Choice` can contain only `int`, `float`, `str`, or `bool`, found values: [[256, 128, 64, 32, 16]]with types: <class 'list'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(\n\u001b[0;32m      2\u001b[0m     xtrain, \n\u001b[0;32m      3\u001b[0m     ytrain,\n\u001b[0;32m      4\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[stop_early]\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:231\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m    230\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[1;32m--> 231\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mon_trial_end(trial)\n\u001b[0;32m    232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mc:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:335\u001b[0m, in \u001b[0;36mBaseTuner.on_trial_end\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_trial_end\u001b[39m(\u001b[39mself\u001b[39m, trial):\n\u001b[0;32m    330\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \n\u001b[0;32m    332\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[39m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 335\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moracle\u001b[39m.\u001b[39;49mend_trial(trial)\n\u001b[0;32m    336\u001b[0m     \u001b[39m# Display needs the updated trial scored by the Oracle.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_display\u001b[39m.\u001b[39mon_trial_end(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id))\n",
      "File \u001b[1;32mc:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\oracle.py:107\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m     LOCKS[oracle]\u001b[39m.\u001b[39macquire()\n\u001b[0;32m    106\u001b[0m     THREADS[oracle] \u001b[39m=\u001b[39m thread_name\n\u001b[1;32m--> 107\u001b[0m ret_val \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    108\u001b[0m \u001b[39mif\u001b[39;00m need_acquire:\n\u001b[0;32m    109\u001b[0m     THREADS[oracle] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\tuners\\gridsearch.py:318\u001b[0m, in \u001b[0;36mGridSearchOracle.end_trial\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[39m@oracle_module\u001b[39m\u001b[39m.\u001b[39msynchronized\n\u001b[0;32m    317\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mend_trial\u001b[39m(\u001b[39mself\u001b[39m, trial):\n\u001b[1;32m--> 318\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mend_trial(trial)\n\u001b[0;32m    319\u001b[0m     \u001b[39m# It is OK for a trial_id to be pushed into _populate_next multiple\u001b[39;00m\n\u001b[0;32m    320\u001b[0m     \u001b[39m# times. It will be skipped during _populate_space if its next\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     \u001b[39m# combination has been tried.\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \n\u001b[0;32m    323\u001b[0m     \u001b[39m# For not blocking _populate_space, we push it regardless of the status.\u001b[39;00m\n\u001b[0;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_populate_next\u001b[39m.\u001b[39mappend(trial\u001b[39m.\u001b[39mtrial_id)\n",
      "File \u001b[1;32mc:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\oracle.py:107\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m     LOCKS[oracle]\u001b[39m.\u001b[39macquire()\n\u001b[0;32m    106\u001b[0m     THREADS[oracle] \u001b[39m=\u001b[39m thread_name\n\u001b[1;32m--> 107\u001b[0m ret_val \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    108\u001b[0m \u001b[39mif\u001b[39;00m need_acquire:\n\u001b[0;32m    109\u001b[0m     THREADS[oracle] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\oracle.py:434\u001b[0m, in \u001b[0;36mOracle.end_trial\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retry(trial):\n\u001b[0;32m    433\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend_order\u001b[39m.\u001b[39mappend(trial\u001b[39m.\u001b[39mtrial_id)\n\u001b[1;32m--> 434\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_consecutive_failures()\n\u001b[0;32m    436\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_trial(trial)\n\u001b[0;32m    437\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n",
      "File \u001b[1;32mc:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\oracle.py:386\u001b[0m, in \u001b[0;36mOracle._check_consecutive_failures\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m     consecutive_failures \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    385\u001b[0m \u001b[39mif\u001b[39;00m consecutive_failures \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_consecutive_failed_trials:\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    387\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNumber of consecutive failures excceeded the limit \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    388\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_consecutive_failed_trials\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[39m+\u001b[39m trial\u001b[39m.\u001b[39mmessage\n\u001b[0;32m    390\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Number of consecutive failures excceeded the limit of 3.\nTraceback (most recent call last):\n  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 235, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 213, in _build_and_fit_model\n    model = self._try_build(hp)\n  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 155, in _try_build\n    model = self._build_hypermodel(hp)\n  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 146, in _build_hypermodel\n    model = self.hypermodel.build(hp)\n  File \"C:\\Users\\berka\\AppData\\Local\\Temp\\ipykernel_4256\\1118035448.py\", line 29, in HyperModel\n    hp_units3 = hyperparameters.Choice('units3', values=[[256,128,64,32,16]])\n  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\hyperparameters\\hyperparameters.py\", line 288, in Choice\n    hp = hp_types.Choice(\n  File \"c:\\Users\\berka\\anaconda3\\envs\\final_prj\\lib\\site-packages\\keras_tuner\\engine\\hyperparameters\\hp_types\\choice_hp.py\", line 65, in __init__\n    raise TypeError(\nTypeError: A `Choice` can contain only `int`, `float`, `str`, or `bool`, found values: [[256, 128, 64, 32, 16]]with types: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    xtrain, \n",
    "    ytrain,\n",
    "    epochs=25,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[stop_early]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hp = tuner.get_best_hyperparameters(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hp.get('units1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hp.get('units2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hp.get('units3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hp.get('learning_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"model_moons.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 53)]         0           []                               \n",
      "                                                                                                  \n",
      " resnet50_input (InputLayer)    [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " densenet121_input (InputLayer)  [(None, 224, 224, 3  0          []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           1728        ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " resnet50 (Functional)          (None, 2048)         23587712    ['resnet50_input[0][0]']         \n",
      "                                                                                                  \n",
      " densenet121 (Functional)       (None, 1024)         7037504     ['densenet121_input[0][0]']      \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 16)           528         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          1049088     ['resnet50[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 512)          524800      ['densenet121[0][0]']            \n",
      "                                                                                                  \n",
      " mobilenet_1.00_224_input (Inpu  [(None, 224, 224, 3  0          []                               \n",
      " tLayer)                        )]                                                                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 8)            136         ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 512)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " mobilenet_1.00_224 (Functional  (None, 1024)        3228864     ['mobilenet_1.00_224_input[0][0]'\n",
      " )                                                               ]                                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 4)            36          ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2052)         0           ['dropout[0][0]',                \n",
      "                                                                  'dropout_1[0][0]',              \n",
      "                                                                  'mobilenet_1.00_224[0][0]',     \n",
      "                                                                  'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 4)            8212        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 35,438,608\n",
      "Trainable params: 1,584,528\n",
      "Non-trainable params: 33,854,080\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# losses in the training history\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m losses \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(model\u001b[39m.\u001b[39;49mhistory\u001b[39m.\u001b[39;49mhistory)\n\u001b[0;32m      3\u001b[0m \u001b[39m# training loss\u001b[39;00m\n\u001b[0;32m      4\u001b[0m loss \u001b[39m=\u001b[39m losses[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues \n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "# losses in the training history\n",
    "losses = pd.DataFrame(model.history.history)\n",
    "# training loss\n",
    "loss = losses['loss'].values \n",
    "# validation loss\n",
    "val_loss = losses['val_loss'].values\n",
    "\n",
    "# epoch number\n",
    "epoch = losses.index.values + np.ones_like(losses.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses against epoch number in log-scale\n",
    "plt.figure(figsize=(8,4),dpi=100)\n",
    "plt.semilogx(epoch, loss, linewidth=1.5, label='loss')\n",
    "plt.semilogx(epoch, val_loss, linewidth=1.5, label='val_loss')\n",
    "\n",
    "plt.xlabel('epoch',fontsize=10)\n",
    "plt.ylabel('loss value',fontsize=10)\n",
    "plt.legend(loc=1,fontsize=10);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_prj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
