{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "#To disable all logging output from TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"transformed_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bleed</th>\n",
       "      <th>grew</th>\n",
       "      <th>itch</th>\n",
       "      <th>elevation</th>\n",
       "      <th>changed</th>\n",
       "      <th>background_mother</th>\n",
       "      <th>background_father</th>\n",
       "      <th>has_sewage_system</th>\n",
       "      <th>region</th>\n",
       "      <th>smoke</th>\n",
       "      <th>gender</th>\n",
       "      <th>pesticide</th>\n",
       "      <th>fitspatrick</th>\n",
       "      <th>hurt</th>\n",
       "      <th>diagnostic</th>\n",
       "      <th>img_id</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.404762</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PAT_169_694_411.png</td>\n",
       "      <td>./cancer/all_cancer_images/PAT_169_694_411.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.511905</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PAT_38_1003_68.png</td>\n",
       "      <td>./cancer/all_cancer_images/PAT_38_1003_68.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.607143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PAT_65_101_847.png</td>\n",
       "      <td>./cancer/all_cancer_images/PAT_65_101_847.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PAT_69_1053_540.png</td>\n",
       "      <td>./cancer/all_cancer_images/PAT_69_1053_540.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PAT_260_400_566.png</td>\n",
       "      <td>./cancer/all_cancer_images/PAT_260_400_566.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0.726190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>PAT_216_331_678.png</td>\n",
       "      <td>./cancer/all_cancer_images/PAT_216_331_678.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>PAT_365_751_709.png</td>\n",
       "      <td>./cancer/all_cancer_images/PAT_365_751_709.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.702381</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>PAT_771_1488_562.png</td>\n",
       "      <td>./cancer/all_cancer_images/PAT_771_1488_562.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0.619048</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>PAT_319_680_832.png</td>\n",
       "      <td>./cancer/all_cancer_images/PAT_319_680_832.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0.678571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>PAT_714_1337_709.png</td>\n",
       "      <td>./cancer/all_cancer_images/PAT_714_1337_709.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  bleed  grew  itch  elevation  changed  background_mother   \n",
       "0    0.404762      0     0     1          0        0                  1  \\\n",
       "1    0.511905      0     0     1          0        0                  1   \n",
       "2    0.607143      0     0     0          0        0                  1   \n",
       "3    0.666667      0     0     1          1        0                  1   \n",
       "4    0.809524      1     0     1          1        0                  1   \n",
       "..        ...    ...   ...   ...        ...      ...                ...   \n",
       "367  0.726190      0     0     0          0        0                  1   \n",
       "368  0.714286      0     1     1          1        0                  1   \n",
       "369  0.702381      0     1     1          1        1                  0   \n",
       "370  0.619048      1     1     1          1        0                  1   \n",
       "371  0.678571      0     1     1          1        1                  1   \n",
       "\n",
       "     background_father  has_sewage_system  region  smoke  gender  pesticide   \n",
       "0                    0                  0       0      0       1          1  \\\n",
       "1                    1                  0       0      0       1          1   \n",
       "2                    0                  1       0      0       0          0   \n",
       "3                    1                  0       0      0       0          0   \n",
       "4                    1                  0       0      0       0          1   \n",
       "..                 ...                ...     ...    ...     ...        ...   \n",
       "367                  1                  0       0      1       1          1   \n",
       "368                  1                  1       0      0       1          0   \n",
       "369                  0                  1       0      1       1          0   \n",
       "370                  1                  1       0      1       0          0   \n",
       "371                  1                  1       0      1       1          1   \n",
       "\n",
       "     fitspatrick  hurt  diagnostic                img_id   \n",
       "0              1     0           0   PAT_169_694_411.png  \\\n",
       "1              1     0           0    PAT_38_1003_68.png   \n",
       "2              1     0           0    PAT_65_101_847.png   \n",
       "3              1     1           0   PAT_69_1053_540.png   \n",
       "4              1     1           0   PAT_260_400_566.png   \n",
       "..           ...   ...         ...                   ...   \n",
       "367            0     0           4   PAT_216_331_678.png   \n",
       "368            1     0           4   PAT_365_751_709.png   \n",
       "369            0     0           4  PAT_771_1488_562.png   \n",
       "370            1     0           4   PAT_319_680_832.png   \n",
       "371            0     0           4  PAT_714_1337_709.png   \n",
       "\n",
       "                                          image_path  \n",
       "0     ./cancer/all_cancer_images/PAT_169_694_411.png  \n",
       "1      ./cancer/all_cancer_images/PAT_38_1003_68.png  \n",
       "2      ./cancer/all_cancer_images/PAT_65_101_847.png  \n",
       "3     ./cancer/all_cancer_images/PAT_69_1053_540.png  \n",
       "4     ./cancer/all_cancer_images/PAT_260_400_566.png  \n",
       "..                                               ...  \n",
       "367   ./cancer/all_cancer_images/PAT_216_331_678.png  \n",
       "368   ./cancer/all_cancer_images/PAT_365_751_709.png  \n",
       "369  ./cancer/all_cancer_images/PAT_771_1488_562.png  \n",
       "370   ./cancer/all_cancer_images/PAT_319_680_832.png  \n",
       "371  ./cancer/all_cancer_images/PAT_714_1337_709.png  \n",
       "\n",
       "[372 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_with_unique(df, column: str):\n",
    "    uniques = df[column].unique()\n",
    "    mapping = dict(zip(uniques, range(0, len(uniques))))\n",
    "    df[column].replace(mapping, inplace=True)\n",
    "    return df\n",
    "replace_with_unique(df, \"diagnostic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naked=df[['region_ABDOMEN', 'region_ARM', 'region_BACK', 'region_CHEST',\n",
    "       'region_EAR', 'region_FACE', 'region_FOOT', 'region_FOREARM',\n",
    "       'region_HAND', 'region_LIP', 'region_NECK', 'region_NOSE',\n",
    "       'region_SCALP', 'region_THIGH', 'age', 'bleed', 'grew', 'itch',\n",
    "       'elevation', 'changed', 'smoke', 'pesticide', 'hurt', 'diagnostic',]]\n",
    "df_naked.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X  = np.array(df.drop(df[[\"diagnostic\",\"img_id\", \"image_path\"]], axis=1))\n",
    "y = np.array(df[\"diagnostic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(372, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(372,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 15)                240       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 128       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 413\n",
      "Trainable params: 413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=X[0].shape))\n",
    "model.add(Dense(units=15, activation='relu'))\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.5999 - accuracy: 0.2020 - val_loss: 1.8925 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.5735 - accuracy: 0.2155 - val_loss: 1.9384 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.5538 - accuracy: 0.2593 - val_loss: 1.9949 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.5350 - accuracy: 0.2660 - val_loss: 2.0395 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.5167 - accuracy: 0.2795 - val_loss: 2.0944 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.4992 - accuracy: 0.3064 - val_loss: 2.1501 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.4800 - accuracy: 0.3098 - val_loss: 2.2105 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.4597 - accuracy: 0.3434 - val_loss: 2.2902 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.4389 - accuracy: 0.3670 - val_loss: 2.3717 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.4182 - accuracy: 0.3771 - val_loss: 2.4336 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3982 - accuracy: 0.4040 - val_loss: 2.4992 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3778 - accuracy: 0.4175 - val_loss: 2.5777 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3568 - accuracy: 0.4444 - val_loss: 2.6483 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3374 - accuracy: 0.4545 - val_loss: 2.7143 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3165 - accuracy: 0.4579 - val_loss: 2.7760 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.2969 - accuracy: 0.4714 - val_loss: 2.8539 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.2778 - accuracy: 0.4646 - val_loss: 2.9258 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.2589 - accuracy: 0.4680 - val_loss: 3.0089 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.2399 - accuracy: 0.4815 - val_loss: 3.0797 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.2218 - accuracy: 0.4848 - val_loss: 3.1249 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.2042 - accuracy: 0.4916 - val_loss: 3.1937 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1866 - accuracy: 0.5051 - val_loss: 3.2410 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1690 - accuracy: 0.4949 - val_loss: 3.3105 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1510 - accuracy: 0.5152 - val_loss: 3.3720 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1348 - accuracy: 0.5354 - val_loss: 3.4190 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1176 - accuracy: 0.5286 - val_loss: 3.4883 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1020 - accuracy: 0.5556 - val_loss: 3.5408 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0870 - accuracy: 0.5455 - val_loss: 3.6182 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0723 - accuracy: 0.5657 - val_loss: 3.6876 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0574 - accuracy: 0.5758 - val_loss: 3.7379 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0437 - accuracy: 0.6027 - val_loss: 3.8059 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0290 - accuracy: 0.6094 - val_loss: 3.8490 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0162 - accuracy: 0.6498 - val_loss: 3.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0038 - accuracy: 0.6532 - val_loss: 3.9694 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9918 - accuracy: 0.6633 - val_loss: 4.0214 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9804 - accuracy: 0.6633 - val_loss: 4.0966 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9681 - accuracy: 0.6835 - val_loss: 4.1372 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9564 - accuracy: 0.7003 - val_loss: 4.1918 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9445 - accuracy: 0.6936 - val_loss: 4.2233 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9350 - accuracy: 0.6936 - val_loss: 4.2639 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9230 - accuracy: 0.6970 - val_loss: 4.3289 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9132 - accuracy: 0.7037 - val_loss: 4.3410 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9027 - accuracy: 0.7138 - val_loss: 4.4212 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8938 - accuracy: 0.6970 - val_loss: 4.4772 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8850 - accuracy: 0.7104 - val_loss: 4.5439 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8741 - accuracy: 0.7172 - val_loss: 4.5781 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8663 - accuracy: 0.7104 - val_loss: 4.6152 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8586 - accuracy: 0.7172 - val_loss: 4.6530 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8488 - accuracy: 0.7205 - val_loss: 4.6951 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8422 - accuracy: 0.7138 - val_loss: 4.7476 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8332 - accuracy: 0.7273 - val_loss: 4.7734 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8276 - accuracy: 0.7104 - val_loss: 4.8048 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8190 - accuracy: 0.7306 - val_loss: 4.8599 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8133 - accuracy: 0.7205 - val_loss: 4.9005 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8079 - accuracy: 0.7340 - val_loss: 4.9192 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8004 - accuracy: 0.7374 - val_loss: 4.9352 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7956 - accuracy: 0.7273 - val_loss: 4.9792 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7901 - accuracy: 0.7273 - val_loss: 4.9736 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7847 - accuracy: 0.7340 - val_loss: 5.0152 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7791 - accuracy: 0.7340 - val_loss: 5.0262 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7745 - accuracy: 0.7374 - val_loss: 4.9980 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7708 - accuracy: 0.7407 - val_loss: 5.0300 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7650 - accuracy: 0.7374 - val_loss: 5.0348 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7613 - accuracy: 0.7340 - val_loss: 5.0642 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/20000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7569 - accuracy: 0.7407 - val_loss: 5.1009 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7529 - accuracy: 0.7374 - val_loss: 5.0895 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7475 - accuracy: 0.7441 - val_loss: 5.1134 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7434 - accuracy: 0.7475 - val_loss: 5.0934 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.7340 - val_loss: 5.1093 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7363 - accuracy: 0.7306 - val_loss: 5.1124 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7329 - accuracy: 0.7441 - val_loss: 5.0646 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7278 - accuracy: 0.7475 - val_loss: 5.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7248 - accuracy: 0.7441 - val_loss: 5.0858 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7201 - accuracy: 0.7475 - val_loss: 5.0806 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7172 - accuracy: 0.7508 - val_loss: 5.0655 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7152 - accuracy: 0.7542 - val_loss: 5.0664 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7095 - accuracy: 0.7542 - val_loss: 5.0527 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7070 - accuracy: 0.7609 - val_loss: 5.0364 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7036 - accuracy: 0.7508 - val_loss: 5.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.7475 - val_loss: 4.9948 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.7643 - val_loss: 4.9914 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6953 - accuracy: 0.7508 - val_loss: 4.9862 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.7542 - val_loss: 4.9779 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.7609 - val_loss: 4.9278 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.7475 - val_loss: 4.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/20000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.7576 - val_loss: 4.9219 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6818 - accuracy: 0.7677 - val_loss: 4.9042 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6778 - accuracy: 0.7677 - val_loss: 4.8960 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6753 - accuracy: 0.7677 - val_loss: 4.8691 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.7710 - val_loss: 4.8664 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.7576 - val_loss: 4.8391 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.7744 - val_loss: 4.8454 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.7542 - val_loss: 4.8066 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6623 - accuracy: 0.7643 - val_loss: 4.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.7609 - val_loss: 4.8056 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.7609 - val_loss: 4.7887 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.7609 - val_loss: 4.8069 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.7643 - val_loss: 4.8218 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.7609 - val_loss: 4.8264 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.7643 - val_loss: 4.8301 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.7710 - val_loss: 4.8079 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.7744 - val_loss: 4.8121 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.7643 - val_loss: 4.8015 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.7710 - val_loss: 4.7987 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6312 - accuracy: 0.7710 - val_loss: 4.7827 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.7811 - val_loss: 4.7927 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.7778 - val_loss: 4.7782 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.7744 - val_loss: 4.7615 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.7879 - val_loss: 4.7669 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.7710 - val_loss: 4.7547 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.7946 - val_loss: 4.7358 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.7845 - val_loss: 4.7310 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.7879 - val_loss: 4.7331 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.7879 - val_loss: 4.7293 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.7879 - val_loss: 4.7119 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6071 - accuracy: 0.7879 - val_loss: 4.7261 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.7912 - val_loss: 4.7116 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.7980 - val_loss: 4.7006 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.8047 - val_loss: 4.7036 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.7946 - val_loss: 4.6943 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/20000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5968 - accuracy: 0.7946 - val_loss: 4.6536 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/20000\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.8047 - val_loss: 4.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.8081 - val_loss: 4.6330 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.7980 - val_loss: 4.6165 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.8013 - val_loss: 4.6552 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5875 - accuracy: 0.8013 - val_loss: 4.6459 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.7879 - val_loss: 4.6163 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.8114 - val_loss: 4.6192 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7980 - val_loss: 4.6278 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.8013 - val_loss: 4.6388 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7879 - val_loss: 4.6203 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.8047 - val_loss: 4.6302 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.8081 - val_loss: 4.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7946 - val_loss: 4.6211 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.8013 - val_loss: 4.6225 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.8148 - val_loss: 4.6344 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.8114 - val_loss: 4.6305 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.8047 - val_loss: 4.6286 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7912 - val_loss: 4.6094 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5636 - accuracy: 0.8081 - val_loss: 4.5570 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.8114 - val_loss: 4.5509 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.8047 - val_loss: 4.5522 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.8114 - val_loss: 4.5529 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.8114 - val_loss: 4.5608 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.8148 - val_loss: 4.5623 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.8047 - val_loss: 4.5849 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.8047 - val_loss: 4.5870 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.8114 - val_loss: 4.5853 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.8215 - val_loss: 4.5927 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.8047 - val_loss: 4.5768 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.8148 - val_loss: 4.5729 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.8249 - val_loss: 4.5715 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.8215 - val_loss: 4.5769 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.8182 - val_loss: 4.5595 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.8081 - val_loss: 4.5817 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.8249 - val_loss: 4.5831 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.8215 - val_loss: 4.5933 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.8114 - val_loss: 4.5825 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.8148 - val_loss: 4.5975 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.8148 - val_loss: 4.6134 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.8081 - val_loss: 4.5445 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.8283 - val_loss: 4.5600 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.8148 - val_loss: 4.5670 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.8081 - val_loss: 4.5541 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.8215 - val_loss: 4.5606 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.8215 - val_loss: 4.5701 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.8148 - val_loss: 4.5743 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.8182 - val_loss: 4.5795 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.8182 - val_loss: 4.5359 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.8182 - val_loss: 4.5507 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.8249 - val_loss: 4.5634 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.8249 - val_loss: 4.5635 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.8114 - val_loss: 4.5595 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.8249 - val_loss: 4.5946 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.8249 - val_loss: 4.5930 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.8182 - val_loss: 4.5924 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.8249 - val_loss: 4.6060 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.8249 - val_loss: 4.6197 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.8182 - val_loss: 4.6124 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.8283 - val_loss: 4.6093 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.8283 - val_loss: 4.5664 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.8283 - val_loss: 4.5674 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.8182 - val_loss: 4.5831 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.8316 - val_loss: 4.5259 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.8249 - val_loss: 4.5717 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.8182 - val_loss: 4.5691 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.8215 - val_loss: 4.5871 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.8283 - val_loss: 4.5798 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.8283 - val_loss: 4.5744 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.8316 - val_loss: 4.5990 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.8316 - val_loss: 4.5773 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.8249 - val_loss: 4.5739 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.8316 - val_loss: 4.5795 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.8384 - val_loss: 4.5975 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.8350 - val_loss: 4.5923 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.8283 - val_loss: 4.5958 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.8350 - val_loss: 4.6183 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.8384 - val_loss: 4.6330 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.8215 - val_loss: 4.6376 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.8350 - val_loss: 4.6174 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.8384 - val_loss: 4.6317 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.8316 - val_loss: 4.6401 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.8316 - val_loss: 4.6257 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.8316 - val_loss: 4.6596 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.8384 - val_loss: 4.6611 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.8418 - val_loss: 4.6624 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.8451 - val_loss: 4.6725 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8418 - val_loss: 4.6523 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8350 - val_loss: 4.6691 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.8418 - val_loss: 4.6852 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.8418 - val_loss: 4.6913 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.8384 - val_loss: 4.6873 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.8350 - val_loss: 4.7281 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8451 - val_loss: 4.7241 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.8451 - val_loss: 4.7122 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.8418 - val_loss: 4.6995 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.8249 - val_loss: 4.6974 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.8384 - val_loss: 4.7101 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.8451 - val_loss: 4.7375 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.8283 - val_loss: 4.7522 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.8552 - val_loss: 4.7285 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8519 - val_loss: 4.7472 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8552 - val_loss: 4.7286 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.8552 - val_loss: 4.7243 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.8586 - val_loss: 4.7309 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.8653 - val_loss: 4.7290 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.8552 - val_loss: 4.7437 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8620 - val_loss: 4.7584 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8586 - val_loss: 4.6905 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.8418 - val_loss: 4.7074 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.8586 - val_loss: 4.7255 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.8519 - val_loss: 4.7288 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.8620 - val_loss: 4.6930 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.8586 - val_loss: 4.6880 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.8519 - val_loss: 4.7130 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8620 - val_loss: 4.6973 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8552 - val_loss: 4.7094 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8653 - val_loss: 4.7271 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8552 - val_loss: 4.7381 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.8653 - val_loss: 4.7488 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8586 - val_loss: 4.7714 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8620 - val_loss: 4.7870 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8620 - val_loss: 4.7801 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8653 - val_loss: 4.7509 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.8653 - val_loss: 4.7539 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8620 - val_loss: 4.7708 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8687 - val_loss: 4.7514 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8721 - val_loss: 4.7534 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8653 - val_loss: 4.7758 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8620 - val_loss: 4.7904 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8687 - val_loss: 4.8110 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8620 - val_loss: 4.7967 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8687 - val_loss: 4.8165 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4114 - accuracy: 0.8620 - val_loss: 4.8291 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8552 - val_loss: 4.8216 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8687 - val_loss: 4.8453 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/20000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8620 - val_loss: 4.8665 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8721 - val_loss: 4.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8721 - val_loss: 4.8229 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8687 - val_loss: 4.8328 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8721 - val_loss: 4.8556 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8653 - val_loss: 4.8854 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8687 - val_loss: 4.8061 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8653 - val_loss: 4.8444 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8653 - val_loss: 4.8450 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8687 - val_loss: 4.8164 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.8687 - val_loss: 4.8344 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8653 - val_loss: 4.8532 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8788 - val_loss: 4.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8687 - val_loss: 4.8545 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8721 - val_loss: 4.9014 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8687 - val_loss: 4.9123 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8687 - val_loss: 4.9251 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8687 - val_loss: 4.8814 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8687 - val_loss: 4.9335 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8721 - val_loss: 4.9113 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8754 - val_loss: 4.9276 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8721 - val_loss: 4.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8788 - val_loss: 4.8821 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8721 - val_loss: 4.9085 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8687 - val_loss: 4.9792 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8754 - val_loss: 4.9647 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8721 - val_loss: 4.9982 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8687 - val_loss: 4.9685 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8822 - val_loss: 5.0033 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8754 - val_loss: 4.9769 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8721 - val_loss: 5.0273 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8687 - val_loss: 5.0216 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8687 - val_loss: 4.9919 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8721 - val_loss: 5.0169 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8822 - val_loss: 5.0484 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8788 - val_loss: 5.0563 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3703 - accuracy: 0.8822 - val_loss: 5.0663 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3706 - accuracy: 0.8788 - val_loss: 5.0812 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8653 - val_loss: 5.0927 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8822 - val_loss: 5.0966 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/20000\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8788 - val_loss: 5.1462 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/20000\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8788 - val_loss: 5.1472 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/20000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1440 - accuracy: 0.9688"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m opt \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mRMSprop()\n\u001b[1;32m      4\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,optimizer\u001b[39m=\u001b[39m opt, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X, y, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m20_000\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_learning_week_09/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_learning_week_09/lib/python3.9/site-packages/keras/engine/training.py:1729\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1714\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1715\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1716\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1717\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1727\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[1;32m   1728\u001b[0m     )\n\u001b[0;32m-> 1729\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1730\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1731\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1732\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1733\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1734\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1735\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1736\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1737\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1738\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1739\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1740\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1741\u001b[0m )\n\u001b[1;32m   1742\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1743\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1744\u001b[0m }\n\u001b[1;32m   1745\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_learning_week_09/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_learning_week_09/lib/python3.9/site-packages/keras/engine/training.py:2067\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2065\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_metrics()\n\u001b[1;32m   2066\u001b[0m \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m-> 2067\u001b[0m     \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   2068\u001b[0m         \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   2069\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   2070\u001b[0m         ):\n\u001b[1;32m   2071\u001b[0m             callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_learning_week_09/lib/python3.9/site-packages/keras/engine/data_adapter.py:1375\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1374\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m original_spe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m   1376\u001b[0m can_run_full_execution \u001b[39m=\u001b[39m (\n\u001b[1;32m   1377\u001b[0m     original_spe \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1378\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m original_spe\n\u001b[1;32m   1380\u001b[0m )\n\u001b[1;32m   1382\u001b[0m \u001b[39mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_learning_week_09/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:647\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    646\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 647\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_value()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    648\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    649\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_learning_week_09/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:777\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    774\u001b[0m   value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_variable_op()\n\u001b[1;32m    775\u001b[0m \u001b[39m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \u001b[39m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m--> 777\u001b[0m \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39;49midentity(value)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_learning_week_09/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep_learning_week_09/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1162\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1157\u001b[0m   arg_names \u001b[39m=\u001b[39m tf_inspect\u001b[39m.\u001b[39mgetargspec(dispatch_target)\u001b[39m.\u001b[39margs\n\u001b[1;32m   1158\u001b[0m   iterable_params \u001b[39m=\u001b[39m [\n\u001b[1;32m   1159\u001b[0m       (name, arg_names\u001b[39m.\u001b[39mindex(name)) \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m iterable_parameters\n\u001b[1;32m   1160\u001b[0m   ]\n\u001b[0;32m-> 1162\u001b[0m \u001b[39m@traceback_utils\u001b[39m\u001b[39m.\u001b[39mfilter_traceback\n\u001b[1;32m   1163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mop_dispatch_handler\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1164\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Call `dispatch_target`, peforming dispatch when appropriate.\"\"\"\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m   \u001b[39m# Type-based dispatch system (dispatch v2):\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "#model.compile(optimizer=Adam(learning_rate=0.01), loss=keras.losses.categorical_crossentropy, metrics=[keras.metrics.categorical_accuracy])\n",
    "opt = tf.keras.optimizers.RMSprop()\n",
    "model.compile(loss='categorical_crossentropy',optimizer= opt, metrics=['accuracy'])\n",
    "history = model.fit(X, y, batch_size=32, epochs=20_000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history[\"val_categorical_accuracy\"]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_moons.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model.predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=ypred[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_week_09",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
