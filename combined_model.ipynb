{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, concatenate, Input, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_path: str, image_dir: str):\n",
    "    \"\"\"\n",
    "    Load data from CSV and images from a directory.\n",
    "\n",
    "    \"\"\"\n",
    "    # Load CSV data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.sample(frac=1).reset_index()\n",
    "    X = np.array(df.drop([\"diagnostic\", \"img_id\", \"index\", \"level_0\"], axis=1))\n",
    "    y = np.array(df[\"diagnostic\"])\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    y = to_categorical(y)\n",
    "\n",
    "    # Load images using ImageDataGenerator\n",
    "    datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    batch_size = 600\n",
    "    target_size = (224, 224)\n",
    "    class_mode = 'categorical'\n",
    "\n",
    "    train_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        directory=image_dir,\n",
    "        x_col=\"img_id\",\n",
    "        y_col=\"diagnostic\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=class_mode,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    xtrain, ytrain = next(train_generator)\n",
    "    return xtrain, ytrain, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet_model(input_shape: tuple):\n",
    "    \"\"\"\n",
    "    Build a ResNet model based on ResNet50 architecture.\n",
    "\n",
    "    \"\"\"\n",
    "    BASE_MODEL = ResNet50(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        pooling='avg',\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    BASE_MODEL.trainable = True\n",
    "\n",
    "    for layer in BASE_MODEL.layers[:-4]:  # Freeze all layers except the last 4\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(BASE_MODEL)\n",
    "    model.add(Dense(units=2048, activation=\"elu\"))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(units=256, activation=\"elu\"))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(units=128, activation=\"elu\"))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_densenet_model(input_shape: tuple):\n",
    "    \"\"\"\n",
    "    Build a DenseNet model based on DenseNet121 architecture.\n",
    "\n",
    "    \"\"\"\n",
    "    BASE_MODEL_DENSENET = DenseNet121(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        pooling='avg',\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    BASE_MODEL_DENSENET.trainable = True\n",
    "\n",
    "    for layer in BASE_MODEL_DENSENET.layers[:-4]:  # Freeze all layers except the last 4\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(BASE_MODEL_DENSENET)\n",
    "    model.add(Dense(units=512, activation=\"elu\"))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(units=256, activation=\"elu\"))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mobilenet_model(input_shape: tuple):\n",
    "    \"\"\"\n",
    "    Build a MobileNet model based on MobileNet architecture.\n",
    "\n",
    "    \"\"\"\n",
    "    BASE_MODEL_MOBILENET = MobileNet(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        pooling='avg',\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    BASE_MODEL_MOBILENET.trainable = True\n",
    "\n",
    "    for layer in BASE_MODEL_MOBILENET.layers[:-4]:  # Freeze all layers except the last 4\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(BASE_MODEL_MOBILENET)\n",
    "    model.add(Dense(units=512, activation=\"elu\"))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(units=256, activation=\"elu\"))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape: np.array):\n",
    "    \"\"\"\n",
    "    Build a CNN model for CSV file.\n",
    "\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    input_cnn = Input(shape=input_shape)\n",
    "    cnn_output = Dense(units=16, activation='elu')(input_cnn)\n",
    "    cnn_output = Dropout(rate=0.5)(cnn_output)\n",
    "    model = Model(inputs=input_cnn, outputs=cnn_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_combined_model(model_1, model_2, model_3, model_4):\n",
    "    \"\"\"\n",
    "    Build a combined model by concatenating ResNet, DenseNet, MobileNet, and CNN models.\n",
    "\n",
    "    \"\"\"\n",
    "    concatenated = concatenate([model_1.output, model_2.output, model_3.output, model_4.output])\n",
    "    combined_output = Dense(units=32, activation='elu')(concatenated)\n",
    "    combined_output = Dense(units=6, activation='softmax')(combined_output)\n",
    "\n",
    "    combined_model = Model(\n",
    "        inputs=[model_1.input, model_2.input, model_3.input, model_4.input],\n",
    "        outputs=[combined_output]\n",
    "    )\n",
    "\n",
    "    return combined_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, xtrain, ytrain, X, y, batch_size, epochs):\n",
    "    \"\"\"\n",
    "    Train the model.\n",
    "\n",
    "    \"\"\"\n",
    "    opt = tf.keras.optimizers.SGD(lr=0.0003)\n",
    "    model.compile(optimizer=opt, loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "    \n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=80)\n",
    "    \n",
    "    history = model.fit([xtrain, xtrain, xtrain, X], ytrain, batch_size=batch_size, epochs=epochs,\n",
    "                        callbacks=[stop_early], validation_split=0.2)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear Keras session\n",
    "K.clear_session()\n",
    "\n",
    "# Load and preprocess the data\n",
    "csv_path = \"Augmentation/train_df.csv\"\n",
    "image_dir = \"cancer/images/train\"\n",
    "xtrain, ytrain, X, y = load_data(csv_path, image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build individual models\n",
    "cnn_model = build_resnet_model(input_shape=(224, 224, 3))\n",
    "densenet_model = build_densenet_model(input_shape=(224, 224, 3))\n",
    "mobilenet_model = build_mobilenet_model(input_shape=(224, 224, 3))\n",
    "cnn_model = build_cnn_model(input_shape=X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build combined model\n",
    "combined_model = build_combined_model(cnn_model, densenet_model, mobilenet_model, cnn_model)\n",
    "combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = train_model(combined_model, xtrain, ytrain, X, y, batch_size=16, epochs=1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "combined_model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as picle\n",
    "\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('model_81.h5')\n",
    "\n",
    "with open('model_81.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_81.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_week_09",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
